{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-dating",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Various functions used in data prep and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-innocent",
   "metadata": {},
   "source": [
    "## Static data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "therapeutic-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(A, B, r_map, column, prefix=''):\n",
    "    '''Uses regx on input dataframe B to create column of positive instances of regx. Column \n",
    "       appended to dataframe A.\n",
    "       Inputs:\n",
    "           A   (dataframe): Master df.\n",
    "           B   (dataframe): Dataframe against which regx will be run.\n",
    "           r_map    (dict): Dictionary of {column_name: regx},\n",
    "           column (string): Column from df B agains regx will be run.\n",
    "           prefix (string): Prefix to be added to newly created column name.\n",
    "       Output:\n",
    "           A.join(B)      : DF A with newly created column appended.\n",
    "    '''\n",
    "    for c,regx in r_map.items():\n",
    "        print(c)\n",
    "        B[f'{prefix}{c}'] = B[column].str.match(regx).fillna(0).astype(int,errors='ignore')\n",
    "\n",
    "    B = B.drop(column,axis=1).groupby('HADM_ID').sum()\n",
    "\n",
    "    missing_patients = set(B.index) - set(A.index)\n",
    "    B = B.drop(missing_patients)\n",
    "    return A.join(B)\n",
    "\n",
    "def get_first(A):\n",
    "    '''Pulls first chronological instance for each HADM_ID of input df.\n",
    "        Input :\n",
    "            A (dataframe)\n",
    "        Output:\n",
    "            A (dataframe): All but first instance per HADM_ID removed.\n",
    "    '''\n",
    "    return A.sort_values(by='CHARTTIME')\\\n",
    "            .drop_duplicates(subset=['HADM_ID','ITEMID'])\\\n",
    "            .set_index('HADM_ID')\n",
    "\n",
    "def fix_height(h):\n",
    "    '''Standardizes height to cm and corrects typographical errors.\n",
    "        Input :\n",
    "            h (int or float): Height in in, ft, or cm\n",
    "        Output:\n",
    "            h (int or float): Height in cm\n",
    "    '''\n",
    "    \n",
    "    if 5 <= h <= 7:\n",
    "        h *= 30.48 # ft to cm\n",
    "    elif 12 <= h <= 30:\n",
    "        h += 100\n",
    "    elif h < 120:\n",
    "        h *= 2.54 # in to cm\n",
    "    elif h > 400:\n",
    "        h /= 2.54\n",
    "    return h\n",
    "\n",
    "def fix_weight(w):\n",
    "    '''Standardizes weight to kg.\n",
    "        Input :\n",
    "            w (int or float): Weight in lb or kg\n",
    "        Output:\n",
    "            w (int or float): Weight in kg\n",
    "    '''\n",
    "    w.VALUENUM = w.VALUENUM/2.2    if w.ITEMID=='Present Weight  (lb)' else w.VALUENUM\n",
    "    w.VALUENUM = w.VALUENUM/35.274 if w.ITEMID=='Present Weight  (oz)' else w.VALUENUM\n",
    "    return w.VALUENUM \n",
    "\n",
    "def get_descriptor(s,descriptor):\n",
    "    '''Confirms if input value matches descriptor.\n",
    "        Inputs:\n",
    "            s (string): Value from series cell.\n",
    "            descriptor (string): Desired value.\n",
    "        Output:\n",
    "            Int: 1 if s matches descriptor, 0 otherwise           \n",
    "    '''\n",
    "    return 1 if s[-len(descriptor):]==descriptor else 0\n",
    "\n",
    "def strip_descriptor(s,descriptor):\n",
    "    '''Removes string matching descriptor from string s if present.\n",
    "        Inputs:\n",
    "            s (string): Value from series cell.\n",
    "            descriptor (string): Desired value.\n",
    "        Output:\n",
    "            s (string): s string with descriptor removed if present. \n",
    "    '''\n",
    "    return s[:-len(descriptor)-1] if s[-len(descriptor):]==descriptor else s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-employment",
   "metadata": {},
   "source": [
    "## Dynamic data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "transparent-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(A):\n",
    "    '''Formats column datatypes.\n",
    "        Input : A (dataframe)\n",
    "        Output: A (dataframe)\n",
    "    '''\n",
    "    A = A[A.HADM_ID.notna()].copy()\n",
    "    A.CHARTTIME = pd.to_datetime(A.CHARTTIME)\n",
    "    A.HADM_ID   = A.HADM_ID.astype(int)\n",
    "    return A\n",
    "\n",
    "def F_to_C(t):\n",
    "    '''Converts Fahrenheit to Celsius.\n",
    "        Input : t (int or float)\n",
    "        Output: t (float)\n",
    "    '''\n",
    "    return (t-32)/1.8\n",
    "\n",
    "def convert_temp(A):\n",
    "    '''Standardizes temperature units to Celsius and addresses entry errors.\n",
    "        Input : A (dataframe)\n",
    "        Output: A (dataframe)\n",
    "    '''\n",
    "    A = A[A.VALUENUM.between(15,120)].copy()\n",
    "    A['TEMP'] = A.apply(lambda t: F_to_C(t.VALUENUM) if t.ITEMID==223761                                  \n",
    "                                                   else t.VALUENUM, axis=1)\n",
    "    A.TEMP = A.apply(lambda t: F_to_C(t.VALUENUM)if t.TEMP > 46 # C recorded as F\n",
    "                                               else t.TEMP, axis=1)\n",
    "    A.TEMP = A.apply(lambda t: t.VALUENUM if t.TEMP < 15        # F recorded as C\n",
    "                                        else t.TEMP, axis=1) \n",
    "    return A\n",
    "\n",
    "def fix_oxy(o):\n",
    "    '''Fixes SaO2 typographical errors (negative and *10)\n",
    "        Input : o (int or float)\n",
    "        Output: o (int or float)\n",
    "    '''\n",
    "    o = -o if o<0 else o      \n",
    "    return o/100 if o>200 else o\n",
    "\n",
    "def get_ts(A,column,c_map,get_labs=False): \n",
    "    '''Creates long-form dataframe of time series of daily mean and counts for\n",
    "       specified column.\n",
    "        Inputs :\n",
    "            A   (dataframe)\n",
    "            column (string): Column from which to calculate means and counts.\n",
    "            c_map    (dict): Dictionary with ITEMID corresponding to column,\n",
    "                             as well as outlier cutoffs.\n",
    "            get_labs (bool): If true, narrows A by ITEMID\n",
    "        Outputs:\n",
    "            A   (dataframe): Long-form df, indexed as (HADM_ID,DATE).\n",
    "    '''\n",
    "    lower, upper = c_map['min'], c_map['max'] # Outlier values\n",
    "    A = A.copy()\n",
    "    A = A[(A.ITEMID==c_map['code'])] if get_labs else A \n",
    "    A = convert_temp(A) if column == 'TEMP' else A\n",
    "    A.VALUENUM = A.VALUENUM.map(fix_oxy) if column == 'SaO2' else A.VALUENUM\n",
    "\n",
    "    A = A[A['VALUENUM'].between(lower,upper)]\n",
    "    first = str(A.CHARTTIME.min().date())\n",
    "\n",
    "    A = A.set_index(['HADM_ID','CHARTTIME']) \\\n",
    "         .groupby('HADM_ID')                  \\\n",
    "         .resample('1440min'                   , # Possible to resample at smaller intervals\n",
    "                   level='CHARTTIME'           ,\n",
    "                   origin=f'{first} 00:00:00')  \\\n",
    "         .agg({'VALUENUM':['mean','count','std']}) \n",
    "    A.columns = A.columns.droplevel()\n",
    "    A.rename(columns={'mean' :f'{column}_MEAN' ,\n",
    "                      'count':f'{column}_COUNT',\n",
    "                      'std'  :f'{column}_SD'  },\n",
    "             inplace=True)\n",
    "    A = A.groupby(['HADM_ID']).ffill()\n",
    "    print(f'saving {column}')\n",
    "    A.to_csv(f'mimic_iii_data/{column}_ts.csv')\n",
    "    \n",
    "    A =  A.reset_index()\\\n",
    "          .set_index(['HADM_ID','CHARTTIME'])\n",
    "    A.index.names = ['HADM_ID','DATE']\n",
    "     \n",
    "    return A\n",
    "\n",
    "def add_rx(A,rx,route,rx_map):\n",
    "    '''Creates long-form time series dataframe of days specified drug class administerd.\n",
    "        Inputs :\n",
    "            A  (dataframe):\n",
    "            rx    (string): Drug class for which ts will be created.\n",
    "            route (string): Specifies drug route when naming column.\n",
    "            rx_map  (dict): Dictionary with regx for each drug class.\n",
    "        Outputs:\n",
    "            A (dataframe) : Long-form df, indexed as (HADM_ID,DATE).\n",
    "    '''\n",
    "    print(rx)\n",
    "    regx = rx_map[rx]\n",
    "    A = A[A['DRUG'].str.match(regx)]\n",
    "    \n",
    "    A = pd.DataFrame(A.apply(lambda t: pd.date_range(t.STARTDATE,\n",
    "                                                     t.ENDDATE,freq='1D' ).date,axis=1)\\\n",
    "                      .explode().drop_duplicates())\n",
    "    A[f'{route}_{rx}'] = 1\n",
    "    A.reset_index(inplace=True)\n",
    "    A.rename(columns={'index':'HADM_ID',0:'DATE'},inplace=True)\n",
    "    return A.set_index(['HADM_ID','DATE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-desperate",
   "metadata": {},
   "source": [
    "## Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "early-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y,y_hat):\n",
    "    '''Calculates and returns Root Mean Square Error between input arrays'''\n",
    "    return ((y-y_hat)**2).sum()/len(y)\n",
    "\n",
    "def MAE(y,y_hat):\n",
    "    '''Calculates and returns Mean Square Error between input arrays'''\n",
    "    return (abs(y-y_hat).sum())/len(y)\n",
    "\n",
    "def evaluate_regression(model,X_train,X_test,y_train,y_test):\n",
    "    '''Fits and evaluates performance of input regression model and returns test \n",
    "       set predictions.\n",
    "        Inputs:\n",
    "            model   (sklearn model)   \n",
    "            X_train, X_test    (df): DF from which model predictions will be obtained\n",
    "            y_train,y_test (series): Observed train and test targets\n",
    "        Output:\n",
    "            y_predict      (series): Values predicted from test set \n",
    "            model   (sklearn model): fit regression model\n",
    "    '''\n",
    "    model     = model.fit(X_train,y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    print(f'Training R2:\\n\\t{model.score(X_train,y_train)}')\n",
    "    print(f'Test R2:\\n\\t{model.score(X_test,y_test)}')\n",
    "    return model.predict(X_test),model\n",
    "\n",
    "def evaluate_classifier(y_hat,y_pred):\n",
    "    '''Calculates, prints, and returs accuracy,precision,recall from input observed \n",
    "       and predicted arrays, prints confusion matrix.\n",
    "    '''\n",
    "    confusion = pd.crosstab(y_hat,y_pred)\n",
    "    confusion.index.name,confusion.columns.name  = 'Observed','Predicted'\n",
    "    \n",
    "    acc = m.accuracy_score(y_hat,y_pred)\n",
    "    rec = m.recall_score(y_hat,y_pred,pos_label=1)\n",
    "    prc = m.precision_score(y_hat,y_pred,pos_label=1)\n",
    "    print(confusion)\n",
    "    print('Accuracy:\\n\\t' ,acc)\n",
    "    print('Recall:\\n\\t'   ,rec)\n",
    "    print('Precision:\\n\\t',prc)\n",
    "    return acc,rec,prc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-republic",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "awful-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(i,batch_size):\n",
    "    '''Creates list of batches, each with a list HADM_IDs to be used in each batch\n",
    "        Inputs:\n",
    "            i (pd multi-index): ('HADM_IDs','DATE')\n",
    "            batch_size (int)        \n",
    "        Outputs:\n",
    "            batches (array): Array of batches. Each sub-array contains HADM_IDs for batch\n",
    "            batch_n   (int): number of batches\n",
    "    '''\n",
    "    hadm_id = i.reset_index().HADM_ID.unique()\n",
    "    batch_n = (len(hadm_id)//batch_size)+1\n",
    "    cutoff  = batch_size*(batch_n-1)\n",
    "    tail    = hadm_id[cutoff:]\n",
    "    batches = np.split(hadm_id[:cutoff],batch_n-1)\n",
    "    batches.append(hadm_id[cutoff:])\n",
    "    return batches, batch_n\n",
    "\n",
    "def batch_generator(X,y,target,batches,columns):\n",
    "    '''Creates batch generator/formatter \n",
    "        Inputs:\n",
    "            X          (df): Feature df\n",
    "            y          (df): Target df\n",
    "            target   (list): list of columns from y to use as training target\n",
    "            batches (array): Array of HADM_IDs for each batch\n",
    "            columns  (list): List of columns from X to use in training\n",
    "        Outputs:\n",
    "            X_batch    (df): Single batch from X\n",
    "            y_batch    (df): Single batch from y\n",
    "    '''\n",
    "    i = 0\n",
    "    while True:\n",
    "        i = 0 if i==len(batches) else i\n",
    "        \n",
    "        batch = batches[i]\n",
    "        X_batch = X.loc[batch,columns]\n",
    "        y_batch = y.loc[batch]\n",
    "\n",
    "        X_batch.reset_index(inplace=True)\n",
    "        hadm_batch = X_batch.HADM_ID.unique()\n",
    "        X_batch.drop('DATE',axis=1,inplace=True)\n",
    "        X_batch.set_index(['HADM_ID',y_batch.DAY_NUMBER],inplace=True)\n",
    "\n",
    "        hadm_n,col_n,row_n = len(hadm_batch),len(columns),max(y.LOS)\n",
    "\n",
    "        index = pd.DataFrame({'HADM_ID':np.repeat(hadm_batch,row_n)})\n",
    "        index['DAY_NUMBER'] = index.groupby('HADM_ID').cumcount()\n",
    "        index.set_index(['HADM_ID','DAY_NUMBER'],inplace=True)\n",
    "\n",
    "        y_batch = y_batch[y_batch.DAY_NUMBER==1][target]\n",
    "        y_batch = y_batch.values.reshape(hadm_n,len(target))\n",
    "\n",
    "        X_batch = index.join(X_batch).fillna(9999)\n",
    "        X_batch = X_batch.values.reshape(hadm_n,row_n,col_n)\n",
    "\n",
    "        i+=1    \n",
    "        yield X_batch,y_batch\n",
    "        \n",
    "def create_lstm(target,columns,batch_size,shape,loss,activations,metrics):\n",
    "    '''Contructs LSTM\n",
    "        Inputs:\n",
    "            target     (list): list of targets to be used in training\n",
    "            columns    (list): list of features to be used in training\n",
    "            batch_size  (int): batch size (number of HADM_ID)\n",
    "            shape     (tuple): shape of training data\n",
    "            loss     (string): desired loss functio\n",
    "            activation (list): [LSTM activation, Output activation]\n",
    "            metrics    (list): List of metrics to calculate during training\n",
    "        Outputs:\n",
    "            model (keras model): compiled model ready to be fit\n",
    "    '''\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Masking(mask_value  = 9999, \n",
    "                      input_shape = shape))\n",
    "    model.add(LSTM(16,\n",
    "                   activation       = activations[0],\n",
    "                   input_shape      = shape         ,\n",
    "                   return_sequences = True)         )\n",
    "    model.add(LSTM(16,\n",
    "                   activation = activations[0]))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(16,\n",
    "                    activation = activations[0]))        \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(len(target), \n",
    "                    activation = activations[1]))\n",
    "\n",
    "    model.compile(loss      = loss   , \n",
    "                  optimizer = 'adam' ,\n",
    "                  metrics   = metrics)\n",
    "    return model\n",
    "\n",
    "def unpack_prediction(prediction,target):\n",
    "    '''Unpacks output LSTM prediction and returns as series with class names.'''\n",
    "    return pd.Series({f'{t}_PREDICTED_PROB':p for t,p in zip(target,prediction.ravel())})\n",
    "\n",
    "def run_model(X,y,target,columns,batch_size,loss,activations,metrics):\n",
    "    '''Creates and trains LSTM model, returns model and validate set predictions.\n",
    "        Inputs:\n",
    "            X              (df): Feature df\n",
    "            y              (df): Target df\n",
    "            target       (list): List of target variables to be used in training\n",
    "            columns      (list): List of features to be used in training\n",
    "            batch_size    (int): Desired batch size\n",
    "            loss       (string): Desired loss funtion\n",
    "            activations  (list): [LSTM activations, final activation]\n",
    "            metrics      (list): List of metrics to calculate during training\n",
    "        Outputs:\n",
    "            model (keras model): Trained LSTM\n",
    "            predicted      (df): DF of predicted values off validation set          \n",
    "    '''\n",
    "    shape = (None,len(columns))\n",
    "    train_batches,train_batch_n = create_batches(train,batch_size)\n",
    "    val_batches  ,val_batch_n   = create_batches(val,batch_size)\n",
    "    \n",
    "    model = create_lstm(target     ,\n",
    "                        columns    ,\n",
    "                        batch_size ,\n",
    "                        shape      ,\n",
    "                        loss       ,\n",
    "                        activations,\n",
    "                        metrics    )\n",
    "    \n",
    "    train_generator = batch_generator(X            ,\n",
    "                                      y            ,\n",
    "                                      target       ,\n",
    "                                      train_batches,\n",
    "                                      columns      )\n",
    "    val_generator   = batch_generator(X            ,\n",
    "                                      y            ,\n",
    "                                      target       ,\n",
    "                                      val_batches  ,\n",
    "                                      columns      )\n",
    "\n",
    "    model.fit(x        = train_generator, \n",
    "              validation_data  = val_generator  ,\n",
    "              validation_steps = val_batch_n    ,\n",
    "              epochs           = 10             ,\n",
    "              steps_per_epoch  = train_batch_n  ) \n",
    "    \n",
    "    predicted_test = X.loc[train.index,columns]\\\n",
    "                                .apply(lambda x: unpack_prediction(model.predict(np.asarray([[x]])),\n",
    "                                                                   target),axis=1)\n",
    "    \n",
    "    predicted_val  = X.loc[val.index,columns]\\\n",
    "                              .apply(lambda x: unpack_prediction(model.predict(np.asarray([[x]])),\n",
    "                                                                 target),axis=1)\n",
    "\n",
    "    return model, predicted_test, predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-immigration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
